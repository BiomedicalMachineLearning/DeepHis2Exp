{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7c316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowing 1142243F\n",
      "Num spots:  4784\n",
      "246\n",
      "216\n",
      "222\n",
      "185\n",
      "77\n",
      "247\n",
      "246\n",
      "255\n",
      "247\n",
      "93\n",
      "246\n",
      "247\n",
      "255\n",
      "245\n",
      "94\n",
      "247\n",
      "246\n",
      "255\n",
      "238\n",
      "88\n",
      "130\n",
      "135\n",
      "132\n",
      "140\n",
      "55\n",
      "Total:  4787\n",
      "Windowing CID4290\n",
      "Num spots:  2714\n",
      "793\n",
      "576\n",
      "1001\n",
      "344\n",
      "Total:  2714\n",
      "Windowing CID4465\n",
      "Num spots:  1310\n",
      "345\n",
      "258\n",
      "149\n",
      "558\n",
      "Total:  1310\n",
      "Windowing CID44971\n",
      "Num spots:  1322\n",
      "491\n",
      "462\n",
      "339\n",
      "30\n",
      "Total:  1322\n",
      "Windowing CID4535\n",
      "Num spots:  1431\n",
      "564\n",
      "232\n",
      "632\n",
      "3\n",
      "Total:  1431\n",
      "Windowing 1160920F\n",
      "Num spots:  4895\n",
      "210\n",
      "251\n",
      "251\n",
      "239\n",
      "83\n",
      "226\n",
      "255\n",
      "232\n",
      "240\n",
      "102\n",
      "231\n",
      "230\n",
      "246\n",
      "247\n",
      "99\n",
      "238\n",
      "246\n",
      "247\n",
      "255\n",
      "93\n",
      "144\n",
      "147\n",
      "164\n",
      "160\n",
      "60\n",
      "Total:  4896\n",
      "Windowing block1\n",
      "Num spots:  3798\n",
      "139\n",
      "205\n",
      "219\n",
      "185\n",
      "10\n",
      "169\n",
      "246\n",
      "247\n",
      "255\n",
      "16\n",
      "189\n",
      "230\n",
      "205\n",
      "233\n",
      "0\n",
      "197\n",
      "156\n",
      "241\n",
      "228\n",
      "0\n",
      "72\n",
      "106\n",
      "129\n",
      "124\n",
      "0\n",
      "Total:  3801\n",
      "Windowing block2\n",
      "Num spots:  3987\n",
      "224\n",
      "247\n",
      "246\n",
      "229\n",
      "208\n",
      "246\n",
      "247\n",
      "231\n",
      "243\n",
      "207\n",
      "211\n",
      "196\n",
      "221\n",
      "195\n",
      "254\n",
      "205\n",
      "81\n",
      "97\n",
      "108\n",
      "92\n",
      "Total:  3988\n",
      "Windowing FFPE\n",
      "Num spots:  2518\n",
      "50\n",
      "190\n",
      "188\n",
      "79\n",
      "0\n",
      "169\n",
      "219\n",
      "216\n",
      "189\n",
      "0\n",
      "182\n",
      "215\n",
      "201\n",
      "192\n",
      "0\n",
      "68\n",
      "138\n",
      "159\n",
      "63\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "Total:  2519\n",
      "Windowing 1168993F\n",
      "Num spots:  4898\n",
      "244\n",
      "249\n",
      "248\n",
      "244\n",
      "68\n",
      "246\n",
      "247\n",
      "255\n",
      "246\n",
      "88\n",
      "247\n",
      "246\n",
      "255\n",
      "237\n",
      "94\n",
      "246\n",
      "251\n",
      "243\n",
      "244\n",
      "93\n",
      "86\n",
      "150\n",
      "154\n",
      "164\n",
      "56\n",
      "Total:  4901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | patch_embedding | Conv2d     | 4.7 K \n",
      "1 | x_embed         | Embedding  | 131 K \n",
      "2 | y_embed         | Embedding  | 131 K \n",
      "3 | vit             | ViT        | 71.4 M\n",
      "4 | mean            | Sequential | 12.3 K\n",
      "5 | disp            | Sequential | 12.3 K\n",
      "6 | pi              | Sequential | 12.3 K\n",
      "7 | coef            | Sequential | 1.1 M \n",
      "8 | gene_head       | Sequential | 14.3 K\n",
      "-----------------------------------------------\n",
      "72.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "72.8 M    Total params\n",
      "291.006   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 36/36 [00:10<00:00,  3.54it/s, mse_loss_step=2.000, bake_loss_step=0.000159, zinb_loss_step=3.290, Train_loss_step=2.820, mse_loss_epoch=4.200, bake_loss_epoch=0.000205, zinb_loss_epoch=5.670, Train_loss_epoch=5.620]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 36/36 [00:11<00:00,  3.10it/s, mse_loss_step=2.000, bake_loss_step=0.000159, zinb_loss_step=3.290, Train_loss_step=2.820, mse_loss_epoch=4.200, bake_loss_epoch=0.000205, zinb_loss_epoch=5.670, Train_loss_epoch=5.620]\n",
      "Training time: 0.003986349370744493 hours\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import time\n",
    "import argparse\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy import stats\n",
    "from copy import deepcopy as dcp\n",
    "from collections import defaultdict as dfd\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from pathlib import Path, PurePath\n",
    "from matplotlib.image import imread\n",
    "from PIL import ImageFile, Image\n",
    "from anndata import AnnData, read_csv, read_text, read_excel, read_mtx, read_loom, read_hdf\n",
    "from anndata import (\n",
    "    AnnData,\n",
    "    read_csv,\n",
    "    read_text,\n",
    "    read_excel,\n",
    "    read_mtx,\n",
    "    read_loom,\n",
    "    read_hdf,\n",
    ")\n",
    "from window_adata import window_adata\n",
    "from HIST2ST import Hist2ST\n",
    "from utils import *\n",
    "\n",
    "# For OOD dataset training\n",
    "from data_vit import ViT_Anndata\n",
    "\n",
    "# Define data directories and sample lists\n",
    "data_dir1 = \"./Alex_NatGen_6BreastCancer/\"\n",
    "data_dir2 = \"./breast_cancer_10x_visium/\"\n",
    "\n",
    "samps1 = [\"1142243F\", \"CID4290\", \"CID4465\", \"CID44971\", \"CID4535\", \"1160920F\"]\n",
    "samps2 = [\"block1\", \"block2\", \"FFPE\"]\n",
    "\n",
    "sampsall = samps1 + samps2\n",
    "samples1 = {i: data_dir1 + i for i in samps1}\n",
    "samples2 = {i: data_dir2 + i for i in samps2}\n",
    "\n",
    "# Marker gene list\n",
    "gene_list = [\n",
    "    \"COX6C\", \"TTLL12\", \"HSP90AB1\", \"TFF3\", \"ATP1A1\", \"B2M\", \"FASN\", \"SPARC\", \"CD74\", \"CD63\", \"CD24\", \"CD81\"\n",
    "]\n",
    "\n",
    "# Load windowed dataset\n",
    "with open('../10x_visium_dataset_without_window.pickle', 'rb') as f:\n",
    "    adata_dict0 = pickle.load(f)\n",
    "\n",
    "for i in samps2:\n",
    "    adata_dict0[i].var_names_make_unique()\n",
    "\n",
    "# Define the gridding size\n",
    "sizes = [4000 for i in range(len(adata_dict0))]\n",
    "\n",
    "# Split tiles into smaller patches according to gridding size\n",
    "adata_dict = window_adata(adata_dict0, sizes)\n",
    "\n",
    "# Define a function to set random seeds\n",
    "def setup_seed(seed=12000):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "# Define a function to calculate correlation between two datasets\n",
    "def get_R(data1, data2, dim=1, func=pearsonr):\n",
    "    adata1 = data1.X\n",
    "    adata2 = data2.X\n",
    "    r1, p1 = [], []\n",
    "    for g in range(data1.shape[dim]):\n",
    "        if dim == 1:\n",
    "            r, pv = func(adata1[:, g], adata2[:, g])\n",
    "        elif dim == 0:\n",
    "            r, pv = func(adata1[g, :], adata2[g, :])\n",
    "        r1.append(r)\n",
    "        p1.append(pv)\n",
    "    r1 = np.array(r1)\n",
    "    p1 = np.array(p1)\n",
    "    return r1, p1\n",
    "\n",
    "# Load and prepare datasets for training\n",
    "def dataset_wrap(dataloader=True):\n",
    "    train_sample = list(set(samps1) - set([\"1160920F\", \"CID4290\"]))  # Alex visium samples\n",
    "    val_sample = [\"1160920F\", \"CID4290\"] # Alex visium samples\n",
    "    test_sample = samps2  # 10x visium samples\n",
    "\n",
    "    tr_name = list(set([i for i in list(adata_dict.keys()) for tr in train_sample if tr in i]))\n",
    "    val_name = list(set([i for i in list(adata_dict.keys()) for val in val_sample if val in i]))\n",
    "    te_name = list(set([i for i in list(adata_dict.keys()) for te in test_sample if te in i]))\n",
    "\n",
    "    trainset = ViT_Anndata(adata_dict=adata_dict, train_set=tr_name, gene_list=gene_list)\n",
    "    valset = ViT_Anndata(adata_dict=adata_dict, train_set=val_name, gene_list=gene_list)\n",
    "    testset = ViT_Anndata(adata_dict=adata_dict, train_set=te_name, gene_list=gene_list)\n",
    "\n",
    "    print(\"LOADED TRAINSET\")\n",
    "    train_loader = DataLoader(trainset, batch_size=1, num_workers=0, shuffle=True)\n",
    "    val_loader = DataLoader(valset, batch_size=1, num_workers=0, shuffle=True)\n",
    "    test_loader = DataLoader(testset, batch_size=1, num_workers=0, shuffle=False)\n",
    "    if dataloader:\n",
    "        return train_loader, val_loader, test_loader\n",
    "    else:\n",
    "        return trainset, valset, testset\n",
    "\n",
    "# Training parameters\n",
    "seed = 12000\n",
    "epochs = 350\n",
    "\n",
    "# Load datasets\n",
    "# train_loader, val_loader, test_loader = dataset_wrap(dataloader=True)\n",
    "\n",
    "# Define the Hist2ST model\n",
    "model = Hist2ST(\n",
    "    depth1=2, depth2=8, depth3=4, n_pos=128,\n",
    "    n_genes=len(gene_list), learning_rate=1e-5,\n",
    "    kernel_size=5, patch_size=7, fig_size=112,\n",
    "    heads=16, channel=32, dropout=0.2,\n",
    "    zinb=0.25, nb=False,\n",
    "    bake=5, lamb=0.5,\n",
    "    policy='mean',\n",
    ")\n",
    "\n",
    "# Set random seed\n",
    "setup_seed(seed)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Setup the PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(accelerator='auto', callbacks=[EarlyStopping(monitor='Train_loss', mode='min')], max_epochs=epochs, logger=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Save model and clean memory\n",
    "gc.collect()\n",
    "del train_loader, test_loader, model\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Training time:\", execution_time/3600, \"hours\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a8245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
