{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: /afm03/Q2/Q2051\n",
      "Start training!\n",
      "Hyperparameters are as follows:\n",
      "Fold: 1\n",
      "Color normalization method: raw\n",
      "Model_name: DeepPT_GNN\n",
      "gene_list: func\n",
      "exp_norm: lognorm\n",
      "cluster: wiener\n",
      "Datasize:6\n",
      "Loading whole slide imgs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:11<00:00,  2.24s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_size: 81\n",
      "subset_size: 48\n",
      "subset_size: 24\n",
      "subset_size: 23\n",
      "subset_size: 20\n",
      "Loading imgs...\n",
      "Loading spatial coordinates...\n",
      "Loading gene expression\n",
      "Loading imgs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 72.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating adjacency matrices or distance matrices...\n",
      "Loading pathology annotations...\n",
      "Loading pathology annotation graph...\n",
      "Datasize:6\n",
      "Loading whole slide imgs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.20s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_size: 96\n",
      "Loading imgs...\n",
      "Loading spatial coordinates...\n",
      "Loading gene expression\n",
      "Loading imgs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 23.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating adjacency matrices or distance matrices...\n",
      "Loading pathology annotations...\n",
      "Loading pathology annotation graph...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import tqdm\n",
    "import torch\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import argparse\n",
    "\n",
    "# Add relative path\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import seed_everything\n",
    "from Models.DeepPT.DeepPT_GNN import *\n",
    "# from Dataloader.Dataset import *\n",
    "from Dataloader.Dataset_wiener import *\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--fold', type=int, default=5, help='dataset fold.')\n",
    "# parser.add_argument('--seed', type=int, default=42, help='random seed.')\n",
    "# parser.add_argument('--colornorm', type=str, default=\"reinhard\", help='Color normalization methods.')\n",
    "# parser.add_argument('--dataset_name', type=str, default=\"SCC_Chenhao\", help='Dataset choice.')\n",
    "# parser.add_argument('--model_name', type=str, default=\"DeepPT_GNN\", help='Model choice.')\n",
    "# parser.add_argument('--gene_list', type=str, default=\"func\", help='Gene list choice.')\n",
    "# parser.add_argument('--hpc', type=str, default=\"wiener\", help='Clusters choice')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# fold = args.fold\n",
    "# seed = args.seed\n",
    "# colornorm = args.colornorm\n",
    "# dataset_name = args.dataset_name\n",
    "# model_name = args.model_name\n",
    "# gene_list = args.gene_list\n",
    "# hpc = args.hpc\n",
    "\n",
    "\"\"\"\n",
    "Hyperparameters settings\n",
    "\"\"\"\n",
    "hpc = \"wiener\"\n",
    "fold = 1\n",
    "seed = 42\n",
    "dataset_name = \"BC_visium\"\n",
    "colornorm = \"raw\"    # \"reinhard\", \"raw\"\n",
    "model_name = \"DeepPT_GNN\"  \n",
    "gene_list = \"func\"\n",
    "exp_norm = \"lognorm\"\n",
    "PAG = True\n",
    "SLG = False\n",
    "HSG = False\n",
    "\n",
    "print(\"Start training!\")\n",
    "print(\"Hyperparameters are as follows:\")\n",
    "print(\"Fold:\", fold)\n",
    "print(\"Color normalization method:\", colornorm)\n",
    "# print(\"Dataset_name:\", dataset_name)\n",
    "print(\"Model_name:\", model_name)\n",
    "print(\"gene_list:\", gene_list)\n",
    "print(\"exp_norm:\", exp_norm)\n",
    "print(\"cluster:\", hpc)\n",
    "\n",
    "if hpc == \"wiener\":\n",
    "    abs_path = \"/afm03/Q2/Q2051/DeepHis2Exp/Models/Benchmarking_main\"\n",
    "    model_weight_path = \"/afm03/Q2/Q2051/DeepHis2Exp/Model_Weights\"\n",
    "   #  model_weight_path = \"/scratch/imb/uqyjia11/Yuanhao/DeepHis2Exp/Model_Weights\"\n",
    "    res_path = \"/afm03/Q2/Q2051/DeepHis2Exp/Results\"\n",
    "    data_path = \"/afm03/Q2/Q2051/DeepHis2Exp/Dataset\"\n",
    "elif hpc == \"vmgpu\":\n",
    "    abs_path = \"/afm01/UQ/Q2051/DeepHis2Exp/Implementation\"\n",
    "    model_weight_path = \"/afm01/UQ/Q2051/DeepHis2Exp/Model_Weights\"\n",
    "    res_path = \"/afm01/UQ/Q2051/DeepHis2Exp/Results\"\n",
    "    data_path = \"/afm01/UQ/Q2051/DeepHis2Exp/Dataset\"\n",
    "elif hpc == \"bunya\":\n",
    "    abs_path = \"/QRISdata/Q2051/DeepHis2Exp/Implementation\"\n",
    "    model_weight_path = \"/QRISdata/Q2051/DeepHis2Exp/Model_Weights\"\n",
    "    res_path = \"/QRISdata/Q2051/DeepHis2Exp/Results\"\n",
    "    data_path = \"/QRISdata/Q2051/DeepHis2Exp/Dataset\"\n",
    "\n",
    "# For reproducing the results\n",
    "seed_everything(seed)\n",
    "\n",
    "# Load train and test dataset and wrap dataloader\n",
    "\n",
    "# Functional genes for visium dataset\n",
    "target_gene_list = list(np.load(f'{data_path}/Gene_list/Gene_list_{gene_list}_{dataset_name}.npy', allow_pickle=True))\n",
    "\n",
    "# Load sample names\n",
    "full_train_dataset = WeightedGraph_Anndata(fold=fold, gene_list=target_gene_list, num_subsets=50,\n",
    "                    train=True, r=112, exp_norm='lognorm', SLG=SLG, HSG=HSG, PAG=PAG,\n",
    "                    neighs=8, color_norm=colornorm, target=target, distance_mode=\"distance\",)\n",
    "tr_loader = DataLoader(full_train_dataset, batch_size=1, shuffle=True)\n",
    "gc.collect()\n",
    "test_dataset = WeightedGraph_Anndata(fold=fold, gene_list=target_gene_list, num_subsets=50,\n",
    "                    train=False, r=112, exp_norm='lognorm', SLG=SLG, HSG=HSG, PAG=PAG,\n",
    "                    neighs=8, color_norm=colornorm, target=target, distance_mode=\"distance\",)\n",
    "te_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | FeatureExtractor | 23.5 M\n",
      "1 | AE                | Autoencoder      | 1.1 M \n",
      "2 | GNN               | GNN              | 23.1 M\n",
      "3 | pred_head         | Linear           | 836 K \n",
      "-------------------------------------------------------\n",
      "48.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "48.5 M    Total params\n",
      "193.930   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19:  68%|██████▊   | 171/250 [00:33<00:15,  5.10it/s, train_loss_step=0.167, mse_step=0.166, recon_loss_step=0.000106, train_loss_epoch=0.148, mse_epoch=0.147, recon_loss_epoch=5.32e-5]  "
     ]
    }
   ],
   "source": [
    "# Define model and train\n",
    "model = CNN_GNN_AE(n_genes=len(target_gene_list), hidden_dim=512, learning_rate=1e-4)\n",
    "    \n",
    "# Empty cache of GPU\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Create folder to save model weights\n",
    "if not os.path.isdir(f\"{model_weight_path}/{dataset_name}/\"):\n",
    "    os.mkdir(f\"{model_weight_path}/{dataset_name}/\")\n",
    "early_stop = pl.callbacks.EarlyStopping(monitor='train_loss', mode='min', patience=10)\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(save_top_k=1, dirpath=f\"{model_weight_path}\", \n",
    "                                                   filename=f\"{model_name}_{dataset_name}_{colornorm}_{test_dataset.te_names}\", \n",
    "                                                   monitor=\"train_loss\", mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(accelerator='auto', \n",
    "                    callbacks=[early_stop, checkpoint_callback], \n",
    "                    max_epochs=100, logger=False)\n",
    "\n",
    "# Start training and save best model\n",
    "trainer.fit(model, tr_loader)\n",
    "\n",
    "# debug\n",
    "# trainer.fit(model, te_loader)\n",
    "\n",
    "print(checkpoint_callback.best_model_path)   # prints path to the best model's checkpoint\n",
    "print(checkpoint_callback.best_model_score) # and prints it score\n",
    "best_model = model.load_state_dict(torch.load(checkpoint_callback.best_model_path)[\"state_dict\"])\n",
    "torch.save(torch.load(checkpoint_callback.best_model_path)[\"state_dict\"], f\"{model_weight_path}/{dataset_name}/{model_name}_PAG{str(PAG)}_HSG{str(HSG)}_{test_dataset.te_names}_{gene_list}.ckpt\")\n",
    "os.remove(checkpoint_callback.best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.zeros(9,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "gc.collect()\n",
    "target_gene_list = test_dataset.gene_set\n",
    "out = trainer.predict(model, te_loader)\n",
    "pred = ad.AnnData(np.concatenate([out[i][0] for i in range(len(out))]))\n",
    "gt_exp = np.concatenate([out[i][1] for i in range(len(out))])\n",
    "gt = sc.concat([test_dataset.meta_dict[sub_slide] for sub_slide in list(test_dataset.meta_dict.keys())])[:,target_gene_list]\n",
    "gt.X = gt_exp\n",
    "        \n",
    "# Add the gene list to AnnData    \n",
    "pred.var_names = target_gene_list\n",
    "gt.var_names = target_gene_list\n",
    "\n",
    "# Save AnnData to H5AD file\n",
    "if not os.path.isdir(f\"{res_path}/{dataset_name}/\"):\n",
    "    os.mkdir(f\"{res_path}/{dataset_name}/\")\n",
    "pred.write(f\"{res_path}/{dataset_name}/pred_{model_name}_{dataset_name}_{colornorm}_{test_dataset.te_names}_{gene_list}.h5ad\")\n",
    "gt.write(f\"{res_path}/{dataset_name}/gt_{model_name}_{dataset_name}_{colornorm}_{test_dataset.te_names}_{gene_list}.h5ad\")\n",
    "gc.collect()\n",
    "\n",
    "# Save spatial location to numpy array\n",
    "spatial_loc = np.concatenate([test_dataset.meta_dict[key].obsm[\"spatial\"] for key in list(test_dataset.meta_dict.keys())])\n",
    "np.save(f'{res_path}/{dataset_name}/spatial_loc_{model_name}_{dataset_name}_{colornorm}_{test_dataset.te_names}_{gene_list}.npy', spatial_loc)\n",
    "gc.collect()\n",
    "\n",
    "print(\"Finish training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "pcc = [pearsonr(gt.X.toarray()[:,g], pred.X[:,g])[0] for g in range(len(target_gene_list))]\n",
    "pcc = np.array(pcc)\n",
    "sns.boxplot(pcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.rand(81, 512)\n",
    "edge_index = test_dataset[0][-2]\n",
    "edge_weights = test_dataset[0][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jk = [gcn(h, edge_index, edge_weights).unsqueeze(0) for gcn in model.GNN.conv]\n",
    "x = torch.cat(jk,0).to(torch.float32)\n",
    "x, _ = nn.LSTM(512, 512, 2)(x)\n",
    "x = x.mean(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
