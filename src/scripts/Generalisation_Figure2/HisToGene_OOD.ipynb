{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206aea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowing 1142243F\n",
      "Num spots:  4784\n",
      "246\n",
      "216\n",
      "222\n",
      "185\n",
      "77\n",
      "247\n",
      "246\n",
      "255\n",
      "247\n",
      "93\n",
      "246\n",
      "247\n",
      "255\n",
      "245\n",
      "94\n",
      "247\n",
      "246\n",
      "255\n",
      "238\n",
      "88\n",
      "130\n",
      "135\n",
      "132\n",
      "140\n",
      "55\n",
      "Total:  4787\n",
      "Windowing CID4290\n",
      "Num spots:  2714\n",
      "793\n",
      "576\n",
      "1001\n",
      "344\n",
      "Total:  2714\n",
      "Windowing CID4465\n",
      "Num spots:  1310\n",
      "345\n",
      "258\n",
      "149\n",
      "558\n",
      "Total:  1310\n",
      "Windowing CID44971\n",
      "Num spots:  1322\n",
      "491\n",
      "462\n",
      "339\n",
      "30\n",
      "Total:  1322\n",
      "Windowing CID4535\n",
      "Num spots:  1431\n",
      "564\n",
      "232\n",
      "632\n",
      "3\n",
      "Total:  1431\n",
      "Windowing 1160920F\n",
      "Num spots:  4895\n",
      "210\n",
      "251\n",
      "251\n",
      "239\n",
      "83\n",
      "226\n",
      "255\n",
      "232\n",
      "240\n",
      "102\n",
      "231\n",
      "230\n",
      "246\n",
      "247\n",
      "99\n",
      "238\n",
      "246\n",
      "247\n",
      "255\n",
      "93\n",
      "144\n",
      "147\n",
      "164\n",
      "160\n",
      "60\n",
      "Total:  4896\n",
      "Windowing block1\n",
      "Num spots:  3798\n",
      "139\n",
      "205\n",
      "219\n",
      "185\n",
      "10\n",
      "169\n",
      "246\n",
      "247\n",
      "255\n",
      "16\n",
      "189\n",
      "230\n",
      "205\n",
      "233\n",
      "0\n",
      "197\n",
      "156\n",
      "241\n",
      "228\n",
      "0\n",
      "72\n",
      "106\n",
      "129\n",
      "124\n",
      "0\n",
      "Total:  3801\n",
      "Windowing block2\n",
      "Num spots:  3987\n",
      "224\n",
      "247\n",
      "246\n",
      "229\n",
      "208\n",
      "246\n",
      "247\n",
      "231\n",
      "243\n",
      "207\n",
      "211\n",
      "196\n",
      "221\n",
      "195\n",
      "254\n",
      "205\n",
      "81\n",
      "97\n",
      "108\n",
      "92\n",
      "Total:  3988\n",
      "Windowing FFPE\n",
      "Num spots:  2518\n",
      "50\n",
      "190\n",
      "188\n",
      "79\n",
      "0\n",
      "169\n",
      "219\n",
      "216\n",
      "189\n",
      "0\n",
      "182\n",
      "215\n",
      "201\n",
      "192\n",
      "0\n",
      "68\n",
      "138\n",
      "159\n",
      "63\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "Total:  2519\n",
      "Windowing 1168993F\n",
      "Num spots:  4898\n",
      "244\n",
      "249\n",
      "248\n",
      "244\n",
      "68\n",
      "246\n",
      "247\n",
      "255\n",
      "246\n",
      "88\n",
      "247\n",
      "246\n",
      "255\n",
      "237\n",
      "94\n",
      "246\n",
      "251\n",
      "243\n",
      "244\n",
      "93\n",
      "86\n",
      "150\n",
      "154\n",
      "164\n",
      "56\n",
      "Total:  4901\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "import time\n",
    "from window_adata import *\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import h5py\n",
    "import json\n",
    "import pickle\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import torchvision\n",
    "import scprep as scp\n",
    "import anndata as ad\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from scipy import stats\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from copy import deepcopy as dcp\n",
    "from collections import defaultdict as dfd\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from pathlib import Path, PurePath\n",
    "from typing import Union, Dict, Optional, Tuple, BinaryIO\n",
    "from matplotlib.image import imread\n",
    "from scanpy import read_visium, read_10x_mtx\n",
    "from PIL import ImageFile, Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from anndata import read as read_h5ad\n",
    "from pathlib import Path, PurePath\n",
    "from typing import Union, Dict, Optional, Tuple, BinaryIO\n",
    "from matplotlib.image import imread\n",
    "import pickle\n",
    "\n",
    "from anndata import (\n",
    "    AnnData,\n",
    "    read_csv,\n",
    "    read_text,\n",
    "    read_excel,\n",
    "    read_mtx,\n",
    "    read_loom,\n",
    "    read_hdf,)\n",
    "\n",
    "\"\"\" Integrate two visium datasets \"\"\"\n",
    "data_dir1 = \"./Alex_NatGen_6BreastCancer/\"\n",
    "data_dir2 = \"./breast_cancer_10x_visium/\"\n",
    "\n",
    "samps1 = [\"1142243F\", \"CID4290\", \"CID4465\", \"CID44971\", \"CID4535\", \"1160920F\"]\n",
    "samps2 = [\"block1\", \"block2\", \"FFPE\"]\n",
    "\n",
    "sampsall = samps1 + samps2\n",
    "samples1 = {i:data_dir1 + i for i in samps1}\n",
    "samples2 = {i:data_dir2 + i for i in samps2}\n",
    "\n",
    "# Marker gene list\n",
    "gene_list = [\"COX6C\",\"TTLL12\", \"HSP90AB1\", \"TFF3\", \"ATP1A1\", \"B2M\", \"FASN\", \"SPARC\", \"CD74\", \"CD63\", \"CD24\", \"CD81\"]\n",
    "\n",
    "# Highly variable genes\n",
    "# with open('../1000hvg_common.pkl', 'rb') as f:\n",
    "#     gene_list = pickle.load(f)\n",
    "# gene_list = list(gene_list)\n",
    "\n",
    "# # Load windowed dataset\n",
    "with open('../10x_visium_dataset_without_window.pickle', 'rb') as f:\n",
    "    adata_dict0 = pickle.load(f)\n",
    "for i in samps2:    \n",
    "    adata_dict0[i].var_names_make_unique()\n",
    "    \n",
    "# Define the gridding size\n",
    "sizes = [4000 for i in range(len(adata_dict0))]\n",
    "\n",
    "# Split tiles into smaller patches according to gridding size\n",
    "adata_dict = window_adata(adata_dict0, sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a84cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training\n",
    "from data_vit import ViT_Anndata\n",
    "\n",
    "def dataset_wrap(dataloader= True):\n",
    "    train_sample = list(set(samps1)-set([\"1160920F\",\"CID4290\"])) # Alex visium samples\n",
    "    val_sample = [\"1160920F\",\"CID4290\"] # Alex visium samples\n",
    "    test_sample = samps2 # 10x visium samples\n",
    "\n",
    "    tr_name = list(set([i for i in list(adata_dict.keys()) for tr in train_sample if tr in i]))\n",
    "    val_name = list(set([i for i in list(adata_dict.keys()) for val in val_sample if val in i]))\n",
    "    te_name = list(set([i for i in list(adata_dict.keys()) for te in test_sample if te in i]))\n",
    "\n",
    "    trainset = ViT_Anndata(adata_dict = adata_dict, train_set = tr_name, gene_list = gene_list, train=True, flatten=False, ori=True, prune='NA', neighs=4, )\n",
    "    valset = ViT_Anndata(adata_dict = adata_dict, train_set = val_name, gene_list = gene_list, train=True, flatten=False, ori=True, prune='NA', neighs=4, )\n",
    "    testset = ViT_Anndata(adata_dict = adata_dict, train_set = te_name, gene_list = gene_list, train=True, flatten=False, ori=True, prune='NA', neighs=4, )\n",
    "\n",
    "    print(\"LOADED TRAINSET\")\n",
    "    train_loader = DataLoader(trainset, batch_size=1, num_workers=0, shuffle=True)\n",
    "    val_loader = DataLoader(valset, batch_size=1, num_workers=0, shuffle=True)\n",
    "    test_loader = DataLoader(testset, batch_size=1, num_workers=0, shuffle=False)\n",
    "    \n",
    "    if dataloader==True:\n",
    "        return train_loader, val_loader, test_loader\n",
    "    else:\n",
    "        return trainset, valset, testset\n",
    "    \n",
    "def get_R(data1,data2,dim=1,func=pearsonr):\n",
    "    adata1=data1.X\n",
    "    adata2=data2.X\n",
    "    r1,p1=[],[]\n",
    "    for g in range(data1.shape[dim]):\n",
    "        if dim==1:\n",
    "            r,pv=func(adata1[:,g],adata2[:,g])\n",
    "        elif dim==0:\n",
    "            r,pv=func(adata1[g,:],adata2[g,:])\n",
    "        r1.append(r)\n",
    "        p1.append(pv)\n",
    "    r1=np.array(r1)\n",
    "    p1=np.array(p1)\n",
    "    return r1,p1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0f62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "\n",
    "from gcn import *\n",
    "from transformer import *\n",
    "from NB_module import *\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy as dcp\n",
    "from collections import defaultdict as dfd\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# set random seed\n",
    "def setup_seed(seed=12000):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "def get_R(data1,data2,dim=1,func=pearsonr):\n",
    "    adata1=data1.X\n",
    "    adata2=data2.X\n",
    "    r1,p1=[],[]\n",
    "    for g in range(data1.shape[dim]):\n",
    "        if dim==1:\n",
    "            r,pv=func(adata1[:,g],adata2[:,g])\n",
    "        elif dim==0:\n",
    "            r,pv=func(adata1[g,:],adata2[g,:])\n",
    "        r1.append(r)\n",
    "        p1.append(pv)\n",
    "    r1=np.array(r1)\n",
    "    p1=np.array(p1)\n",
    "    return r1,p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af9001",
   "metadata": {},
   "source": [
    "# HisToGene Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c859598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from vis_model import HisToGene\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817a6743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval set:  ['CID4465_0', '1142243F_23', '1142243F_2', 'CID4465_3', '1142243F_20', '1142243F_21', '1142243F_8', '1142243F_10', '1142243F_24', '1142243F_0', '1142243F_1', '1142243F_16', 'CID44971_1', '1142243F_12', '1142243F_18', 'CID4535_0', 'CID4535_2', '1142243F_3', 'CID44971_0', 'CID4465_1', '1142243F_22', '1142243F_15', '1142243F_6', 'CID4465_2', 'CID44971_2', 'CID4535_1', '1142243F_7', '1142243F_17', '1142243F_5', '1142243F_13', '1142243F_14', '1142243F_4', '1142243F_9', '1142243F_11', '1142243F_19', 'CID44971_3']\n",
      "Loading imgs...\n",
      "Eval set:  ['CID4290_2', '1160920F_21', 'CID4290_1', '1160920F_8', '1160920F_24', '1160920F_4', '1160920F_19', '1160920F_1', '1160920F_14', '1160920F_17', '1160920F_12', '1160920F_13', '1160920F_7', '1160920F_20', '1160920F_2', 'CID4290_3', '1160920F_5', '1160920F_0', '1160920F_3', '1160920F_11', 'CID4290_0', '1160920F_23', '1160920F_22', '1160920F_16', '1160920F_15', '1160920F_18', '1160920F_6', '1160920F_9', '1160920F_10']\n",
      "Loading imgs...\n",
      "Eval set:  ['block1_5', 'block1_2', 'FFPE_6', 'block1_15', 'FFPE_3', 'block1_0', 'block2_2', 'block2_16', 'FFPE_8', 'FFPE_7', 'block1_21', 'FFPE_5', 'block2_8', 'block1_8', 'block2_12', 'block1_22', 'FFPE_2', 'block1_9', 'FFPE_11', 'FFPE_12', 'block1_17', 'block2_0', 'block1_16', 'FFPE_16', 'block2_7', 'block2_3', 'block1_18', 'block2_19', 'block2_17', 'FFPE_10', 'block2_14', 'FFPE_17', 'block1_1', 'block2_9', 'block2_5', 'block2_18', 'block1_6', 'FFPE_13', 'block1_7', 'block1_13', 'block2_13', 'FFPE_18', 'block1_11', 'FFPE_1', 'block2_15', 'block2_1', 'block2_4', 'block2_6', 'FFPE_0', 'block1_23', 'block1_12', 'block1_3', 'block2_10', 'block1_20', 'FFPE_15', 'block1_10', 'block2_11']\n",
      "Loading imgs...\n",
      "LOADED TRAINSET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | patch_embedding | Linear     | 38.5 M\n",
      "1 | x_embed         | Embedding  | 131 K \n",
      "2 | y_embed         | Embedding  | 131 K \n",
      "3 | vit             | ViT        | 67.2 M\n",
      "4 | gene_head       | Sequential | 14.3 K\n",
      "-----------------------------------------------\n",
      "105 M     Trainable params\n",
      "0         Non-trainable params\n",
      "105 M     Total params\n",
      "423.948   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 36/36 [00:11<00:00,  3.18it/s]                   \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▎         | 1/29 [00:00<00:00, 94.58it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▋         | 2/29 [00:00<00:00, 28.99it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█         | 3/29 [00:00<00:01, 19.18it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▍        | 4/29 [00:00<00:01, 19.54it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|█▋        | 5/29 [00:00<00:01, 14.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██        | 6/29 [00:00<00:01, 15.80it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|██▍       | 7/29 [00:00<00:01, 16.46it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|██▊       | 8/29 [00:00<00:01, 15.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|███       | 9/29 [00:00<00:01, 15.86it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|███▍      | 10/29 [00:00<00:01, 14.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|███▊      | 11/29 [00:00<00:01, 12.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|████▏     | 12/29 [00:00<00:01, 12.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████▍     | 13/29 [00:00<00:01, 13.14it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████▊     | 14/29 [00:01<00:01, 13.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|█████▏    | 15/29 [00:01<00:01, 13.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████▌    | 16/29 [00:01<00:00, 13.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████▊    | 17/29 [00:01<00:00, 14.22it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 18/29 [00:01<00:00, 14.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████▌   | 19/29 [00:01<00:00, 14.11it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 20/29 [00:01<00:00, 14.66it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████▏  | 21/29 [00:01<00:00, 13.61it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|███████▌  | 22/29 [00:01<00:00, 13.96it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|███████▉  | 23/29 [00:01<00:00, 14.19it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 24/29 [00:01<00:00, 13.70it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|████████▌ | 25/29 [00:01<00:00, 13.90it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████▉ | 26/29 [00:01<00:00, 13.81it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████▎| 27/29 [00:02<00:00, 13.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|█████████▋| 28/29 [00:02<00:00, 13.29it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 36/36 [00:13<00:00,  2.65it/s]0:00, 13.53it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 36/36 [00:02<00:00, 17.64it/s]                \u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▎         | 1/29 [00:00<00:00, 87.25it/s]\u001b[A\n",
      "Validation DataLoader 0:   7%|▋         | 2/29 [00:00<00:00, 50.68it/s]\u001b[A\n",
      "Validation DataLoader 0:  10%|█         | 3/29 [00:00<00:00, 31.03it/s]\u001b[A\n",
      "Validation DataLoader 0:  14%|█▍        | 4/29 [00:00<00:00, 32.57it/s]\u001b[A\n",
      "Validation DataLoader 0:  17%|█▋        | 5/29 [00:00<00:00, 27.79it/s]\u001b[A\n",
      "Validation DataLoader 0:  21%|██        | 6/29 [00:00<00:00, 28.75it/s]\u001b[A\n",
      "Validation DataLoader 0:  24%|██▍       | 7/29 [00:00<00:00, 26.34it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|██▊       | 8/29 [00:00<00:00, 27.31it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|███       | 9/29 [00:00<00:00, 26.65it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|███▍      | 10/29 [00:00<00:00, 25.30it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|███▊      | 11/29 [00:00<00:00, 24.52it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|████▏     | 12/29 [00:00<00:00, 24.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  45%|████▍     | 13/29 [00:00<00:00, 25.67it/s]\u001b[A\n",
      "Validation DataLoader 0:  48%|████▊     | 14/29 [00:00<00:00, 24.71it/s]\u001b[A\n",
      "Validation DataLoader 0:  52%|█████▏    | 15/29 [00:00<00:00, 23.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  55%|█████▌    | 16/29 [00:00<00:00, 23.41it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████▊    | 17/29 [00:00<00:00, 22.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|██████▏   | 18/29 [00:00<00:00, 23.43it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████▌   | 19/29 [00:00<00:00, 23.01it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 20/29 [00:00<00:00, 23.53it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████▏  | 21/29 [00:00<00:00, 23.15it/s]\u001b[A\n",
      "Validation DataLoader 0:  76%|███████▌  | 22/29 [00:00<00:00, 22.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  79%|███████▉  | 23/29 [00:01<00:00, 22.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 24/29 [00:01<00:00, 23.27it/s]\u001b[A\n",
      "Validation DataLoader 0:  86%|████████▌ | 25/29 [00:01<00:00, 22.47it/s]\u001b[A\n",
      "Validation DataLoader 0:  90%|████████▉ | 26/29 [00:01<00:00, 22.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  93%|█████████▎| 27/29 [00:01<00:00, 22.38it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|█████████▋| 28/29 [00:01<00:00, 22.68it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 36/36 [00:03<00:00, 10.64it/s]0:00, 22.52it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 36/36 [00:03<00:00, 10.63it/s]                \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 57/57 [00:04<00:00, 12.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8208631277084351     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8208631277084351    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  0.029588256345854866  hours\n"
     ]
    }
   ],
   "source": [
    "# OOD training strategy\n",
    "tag = '-htg_her2st_785_32_cv'\n",
    "\n",
    "\"\"\"For training only\"\"\"\n",
    "import gc\n",
    "from data_vit import ViT_Anndata\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\"\"\"Training loops\"\"\"\n",
    "seed=12000\n",
    "epochs=100\n",
    "\n",
    "\"\"\"Load dataset\"\"\"\n",
    "train_loader, val_loader, test_loader = dataset_wrap(dataloader=True)\n",
    "\n",
    "\"\"\"Define model\"\"\"\n",
    "model = HisToGene(n_layers=8, n_genes=len(gene_list), learning_rate=1e-5)\n",
    "setup_seed(seed)\n",
    "\n",
    "\"\"\"Setup trainer\"\"\"\n",
    "trainer = pl.Trainer(accelerator='auto', max_epochs=epochs, logger=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "\"\"\"Save model and clean memory\"\"\"\n",
    "# torch.save(model.state_dict(),f\"./model/HisToGene-OOD.ckpt\")\n",
    "trainer.test(model, test_loader)\n",
    "gc.collect()\n",
    "del train_loader, model\n",
    "    \n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Training time: \", execution_time/3600, \" hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6817282",
   "metadata": {},
   "source": [
    "# HisToGene Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf395558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing\n",
    "\n",
    "from data_vit import ViT_Anndata\n",
    "\n",
    "def dataset_wrap(fold = 0, dataloader= True):\n",
    "    test_sample = sampsall[fold]\n",
    "    print(f\"Test sample: {test_sample}\")\n",
    "    te_name = list(set([i for i in list(adata_dict0.keys()) if test_sample in i]))\n",
    "    testset = ViT_Anndata(adata_dict = adata_dict0, train_set = te_name, gene_list = gene_list, train=True, flatten=False, ori=True, prune='NA', neighs=4, )\n",
    "    test_loader = DataLoader(testset, batch_size=1, num_workers=0, shuffle=False)\n",
    "    if dataloader==True:\n",
    "        return test_loader\n",
    "    else:\n",
    "        return testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "040e52b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(name, model, test_loader):\n",
    "    model.eval()\n",
    "    device = 'cpu'\n",
    "    for patch, center, exp, adj, label, oris, sfs, *_ in test_loader:\n",
    "        adj=adj.squeeze(0)\n",
    "        exp=exp.squeeze(0)\n",
    "        ct = center.squeeze().cpu().numpy()\n",
    "        gts = exp.squeeze().cpu().numpy()\n",
    "\n",
    "        \"\"\"Model inference\"\"\"\n",
    "        gene_exp = model(patch, center).squeeze(0)\n",
    "\n",
    "        \"\"\"Put prediction into adata\"\"\"\n",
    "        pred = ad.AnnData(gene_exp.cpu().detach().numpy())\n",
    "        \n",
    "        # Marker Genes\n",
    "        gene_list = [\"COX6C\",\"TTLL12\", \"HSP90AB1\", \"TFF3\", \"ATP1A1\", \"B2M\", \"FASN\", \"SPARC\", \"CD74\", \"CD63\", \"CD24\", \"CD81\"]\n",
    "        \n",
    "        pred.var_names = gene_list\n",
    "        pred.obsm['spatial'] = ct\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ea601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample: 1142243F\n",
      "Eval set:  ['1142243F']\n",
      "Loading imgs...\n",
      "Test sample: CID4290\n",
      "Eval set:  ['CID4290']\n",
      "Loading imgs...\n",
      "Test sample: CID4465\n",
      "Eval set:  ['CID4465']\n",
      "Loading imgs...\n",
      "Test sample: CID44971\n",
      "Eval set:  ['CID44971']\n",
      "Loading imgs...\n",
      "Test sample: CID4535\n",
      "Eval set:  ['CID4535']\n",
      "Loading imgs...\n",
      "Test sample: 1160920F\n",
      "Eval set:  ['1160920F']\n",
      "Loading imgs...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"For OOD test only\"\"\"\n",
    "import gc\n",
    "from vis_model import HisToGene\n",
    "from data_vit import ViT_Anndata\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\"\"\"Training loops\"\"\"\n",
    "for fold in range(9):\n",
    "    \"\"\"print sample name\"\"\"\n",
    "    name = sampsall[fold]\n",
    "    \n",
    "    \"\"\"Reproducibility\"\"\"\n",
    "    setup_seed(12000)\n",
    "    \n",
    "    \"\"\"Load dataset\"\"\"\n",
    "    test_loader = dataset_wrap(fold = fold, dataloader= True)\n",
    "    \"\"\"Define model\"\"\"\n",
    "    model = HisToGene(n_layers=8, n_genes=len(gene_list), learning_rate=1e-5)\n",
    "# #     model.load_state_dict(torch.load(f\"./model/HisToGene-OOD.ckpt\"))\n",
    "\n",
    "    \"\"\"Test model performance\"\"\"\n",
    "    pred = test(name, model, test_loader)\n",
    "    df = pred.var\n",
    "    df[\"Gene\"] = df.index\n",
    "    df[\"Slide\"] = name\n",
    "    df[\"Method\"] = f\"HisToGene\"\n",
    "    \n",
    "    import os\n",
    "    directory = f\"./Results/PCC_table\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    df.to_csv(f\"./Results/PCC_table/{name}_PCC_HisToGene-OOD.csv\")\n",
    "    gc.collect()\n",
    "    del test_loader, model\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Inference time: \", execution_time/3600, \" hours\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017dfba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = []\n",
    "for name in [\"1160920F\",\"CID4290\"]:\n",
    "    df = pd.read_csv(f\"./Results/PCC_table/{name}_PCC_HisToGene-OOD.csv\", index_col=0)\n",
    "    df1.append(df)\n",
    "df_train = pd.concat(df1).reset_index()\n",
    "df_train[\"Kind\"] = \"Training dataset (6 samples)\"\n",
    "\n",
    "df1 = []\n",
    "for name in samps2:\n",
    "    df = pd.read_csv(f\"./Results/PCC_table/{name}_PCC_HisToGene-OOD.csv\", index_col=0)\n",
    "    df1.append(df)\n",
    "df_test = pd.concat(df1).reset_index()\n",
    "df_test[\"Kind\"] = \"Test dataset (3 samples)\"\n",
    "\n",
    "df_all = pd.concat([df_train, df_test]).reset_index()\n",
    "df_all.to_csv(f\"./Results/PCC_table/HisToGene_visium_MarkerGenes-OOD.csv\")\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861fc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.set_style(\"white\")\n",
    "ax = sns.boxplot(x=\"Kind\", y=\"Pearson correlation\", hue=\"Method\", data=df_all,showfliers=False, orient=\"v\", palette = \"Set2\")   \n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax.set(xlabel=None)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Pearson R\")\n",
    "plt.title(\"Assessment of model generalization capabilities on OOD dataset \\n (Predict maker genes only)\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"./Figure4.png\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac982045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
