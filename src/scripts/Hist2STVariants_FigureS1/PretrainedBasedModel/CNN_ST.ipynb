{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55836ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pytorch_lightning as pl\n",
    "import scanpy as sc\n",
    "import scprep as scp\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict as dfd\n",
    "from copy import deepcopy as dcp\n",
    "from pathlib import Path, PurePath\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile, Image\n",
    "from matplotlib.image import imread\n",
    "from scanpy import read_10x_mtx, read_visium\n",
    "from torch.utils.data import DataLoader\n",
    "from window_adata import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2515f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install squidpy\n",
    "# !pip install pytorch_lightning\n",
    "# !pip install scprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969150a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowing 1142243F\n",
      "Num spots:  4784\n",
      "246\n",
      "216\n",
      "222\n",
      "185\n",
      "77\n",
      "247\n",
      "246\n",
      "255\n",
      "247\n",
      "93\n",
      "246\n",
      "247\n",
      "255\n",
      "245\n",
      "94\n",
      "247\n",
      "246\n",
      "255\n",
      "238\n",
      "88\n",
      "130\n",
      "135\n",
      "132\n",
      "140\n",
      "55\n",
      "Total:  4787\n",
      "Windowing CID4290\n",
      "Num spots:  2714\n",
      "793\n",
      "576\n",
      "1001\n",
      "344\n",
      "Total:  2714\n",
      "Windowing CID4465\n",
      "Num spots:  1310\n",
      "345\n",
      "258\n",
      "149\n",
      "558\n",
      "Total:  1310\n",
      "Windowing CID44971\n",
      "Num spots:  1322\n",
      "491\n",
      "462\n",
      "339\n",
      "30\n",
      "Total:  1322\n",
      "Windowing CID4535\n",
      "Num spots:  1431\n",
      "564\n",
      "232\n",
      "632\n",
      "3\n",
      "Total:  1431\n",
      "Windowing 1160920F\n",
      "Num spots:  4895\n",
      "210\n",
      "251\n",
      "251\n",
      "239\n",
      "83\n",
      "226\n",
      "255\n",
      "232\n",
      "240\n",
      "102\n",
      "231\n",
      "230\n",
      "246\n",
      "247\n",
      "99\n",
      "238\n",
      "246\n",
      "247\n",
      "255\n",
      "93\n",
      "144\n",
      "147\n",
      "164\n",
      "160\n",
      "60\n",
      "Total:  4896\n",
      "Windowing block1\n",
      "Num spots:  3798\n",
      "139\n",
      "205\n",
      "219\n",
      "185\n",
      "10\n",
      "169\n",
      "246\n",
      "247\n",
      "255\n",
      "16\n",
      "189\n",
      "230\n",
      "205\n",
      "233\n",
      "0\n",
      "197\n",
      "156\n",
      "241\n",
      "228\n",
      "0\n",
      "72\n",
      "106\n",
      "129\n",
      "124\n",
      "0\n",
      "Total:  3801\n",
      "Windowing block2\n",
      "Num spots:  3987\n",
      "224\n",
      "247\n",
      "246\n",
      "229\n",
      "208\n",
      "246\n",
      "247\n",
      "231\n",
      "243\n",
      "207\n",
      "211\n",
      "196\n",
      "221\n",
      "195\n",
      "254\n",
      "205\n",
      "81\n",
      "97\n",
      "108\n",
      "92\n",
      "Total:  3988\n",
      "Windowing FFPE\n",
      "Num spots:  2518\n",
      "50\n",
      "190\n",
      "188\n",
      "79\n",
      "0\n",
      "169\n",
      "219\n",
      "216\n",
      "189\n",
      "0\n",
      "182\n",
      "215\n",
      "201\n",
      "192\n",
      "0\n",
      "68\n",
      "138\n",
      "159\n",
      "63\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "Total:  2519\n",
      "Windowing 1168993F\n",
      "Num spots:  4898\n",
      "244\n",
      "249\n",
      "248\n",
      "244\n",
      "68\n",
      "246\n",
      "247\n",
      "255\n",
      "246\n",
      "88\n",
      "247\n",
      "246\n",
      "255\n",
      "237\n",
      "94\n",
      "246\n",
      "251\n",
      "243\n",
      "244\n",
      "93\n",
      "86\n",
      "150\n",
      "154\n",
      "164\n",
      "56\n",
      "Total:  4901\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Integrate two visium datasets \"\"\"\n",
    "data_dir1 = \"./Alex_NatGen_6BreastCancer/\"\n",
    "data_dir2 = \"./breast_cancer_10x_visium/\"\n",
    "\n",
    "samps1 = [\"1142243F\", \"CID4290\", \"CID4465\", \"CID44971\", \"CID4535\", \"1160920F\"]\n",
    "samps2 = [\"block1\", \"block2\", \"FFPE\",]\n",
    "\n",
    "sampsall = samps1 + samps2\n",
    "samples1 = {i:data_dir1 + i for i in samps1}\n",
    "samples2 = {i:data_dir2 + i for i in samps2}\n",
    "\n",
    "# Marker gene list\n",
    "gene_list = [\"COX6C\",\"TTLL12\", \"HSP90AB1\", \"TFF3\", \"ATP1A1\", \"B2M\", \"FASN\", \"SPARC\", \"CD74\", \"CD63\", \"CD24\", \"CD81\"]\n",
    "\n",
    "# # Load windowed dataset\n",
    "import pickle\n",
    "with open('10x_visium_dataset_without_window.pickle', 'rb') as f:\n",
    "    adata_dict0 = pickle.load(f)\n",
    "    \n",
    "# Define the gridding size\n",
    "sizes = [4000 for i in range(len(adata_dict0))]\n",
    "\n",
    "# Split tiles into smaller patches according to gridding size\n",
    "adata_dict = window_adata(adata_dict0, sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f28c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training\n",
    "from data_vit import ViT_Anndata\n",
    "\n",
    "def dataset_wrap(fold = 0, train=True, dataloader=True):\n",
    "    test_sample = sampsall[fold]\n",
    "    test_sample_orig = sampsall[fold] # Split one sample as test sample\n",
    "    val_sample = list(set(sampsall)-set(sampsall[fold]))[:3] # Split 3 samples as validation samples\n",
    "    train_sample = list(set(sampsall)-set(test_sample)-set(val_sample)) # Other samples are training samples\n",
    "\n",
    "    tr_name = list(set([i for i in list(adata_dict.keys()) for tr in train_sample if tr in i]))\n",
    "    val_name = list(set([i for i in list(adata_dict.keys()) for val in val_sample if val in i]))\n",
    "    te_name = list(set([i for i in list(adata_dict.keys()) if test_sample in i]))\n",
    "    if train:\n",
    "        print(\"LOADED TRAINSET\")\n",
    "        trainset = ViT_Anndata(adata_dict = adata_dict, train_set = tr_name, gene_list = gene_list, train=True, flatten=False, ori=True, prune='NA', neighs=4, )\n",
    "        valset = ViT_Anndata(adata_dict = adata_dict, train_set = val_name, gene_list = gene_list, train=True, flatten=False, ori=True, prune='NA', neighs=4, )\n",
    "        train_loader = DataLoader(trainset, batch_size=1, num_workers=0, shuffle=True)\n",
    "        val_loader = DataLoader(valset, batch_size=1, num_workers=0, shuffle=False)\n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    else:\n",
    "        print(\"LOADED TESTSET\")\n",
    "        testset = ViT_Anndata(adata_dict = adata_dict, train_set = te_name, gene_list = gene_list, train=True, flatten=False, ori=True, prune='NA', neighs=4, )\n",
    "        test_loader = DataLoader(testset, batch_size=1, num_workers=0, shuffle=False)\n",
    "        return test_loader\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a5e77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms as tf\n",
    "import torch.nn as nn\n",
    "\n",
    "# Import custom modules\n",
    "from gcn import *\n",
    "from NB_module import *\n",
    "from transformer import *\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import deepcopy as dcp\n",
    "from collections import defaultdict as dfd\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "\n",
    "# Import torchvision models and transforms\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Define a function to set a random seed for reproducibility\n",
    "def setup_seed(seed=12000):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "# Define a function to calculate Pearson correlation coefficient\n",
    "def get_R(data1, data2, dim=1, func=pearsonr):\n",
    "    # Calculate Pearson correlation coefficient for each gene\n",
    "    adata1 = data1.X\n",
    "    adata2 = data2.X\n",
    "    r1, p1 = [], []\n",
    "    for g in range(data1.shape[dim]):\n",
    "        if dim == 1:\n",
    "            r, pv = func(adata1[:, g], adata2[:, g])\n",
    "        elif dim == 0:\n",
    "            r, pv = func(adata1[g, :], adata2[g, :])\n",
    "        r1.append(r)\n",
    "        p1.append(pv)\n",
    "    r1 = np.array(r1)\n",
    "    p1 = np.array(p1)\n",
    "    return r1, p1\n",
    "\n",
    "# Define a function to fine-tune a pretrained model\n",
    "def ft_extra(name=\"resnet\"):\n",
    "    if name == \"resnet\":\n",
    "        model_ft = torchvision.models.resnet50(weights=models.ResNet50_Weights)\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = False\n",
    "        model_ft.fc = nn.Sequential(nn.Identity())\n",
    "        dim = 2048\n",
    "    elif name == \"efficient\":\n",
    "        model_ft = torchvision.models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights)\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = False\n",
    "        model_ft.classifier = nn.Sequential(nn.Identity())\n",
    "        dim = 1280\n",
    "    elif name == 'swin':\n",
    "        model_ft = torchvision.models.swin_s(weights=models.Swin_S_Weights)\n",
    "        for param in model_ft.parameters():\n",
    "            param.requires_grad = False\n",
    "        model_ft.head = nn.Sequential(nn.Identity())\n",
    "        dim = 768\n",
    "    return model_ft, dim\n",
    "\n",
    "# Define a custom Vision Transformer (ViT) class\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, name=\"resnet\", dim=1024,\n",
    "                 depth1=2, depth2=8, depth3=4, \n",
    "                 heads=8, dim_head=64, mlp_dim=1024,\n",
    "                 policy='mean', gcn=True\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize with the given hyperparameters\n",
    "        self.ft_extractor, ft_dim = ft_extra(name=name)  # Feature extractor and its output dimension\n",
    "        self.projection = nn.Sequential(nn.Linear(ft_dim, dim))  # Linear projection layer\n",
    "        self.transformer = nn.Sequential(*[attn_block(dim, heads, dim_head, mlp_dim, 0.2) for i in range(depth2)])  # Transformer blocks\n",
    "        self.GCN = nn.ModuleList([gs_block(dim, dim, policy, gcn) for i in range(depth3)])  # Graph Convolutional Network blocks\n",
    "        self.jknet = nn.Sequential(\n",
    "            nn.LSTM(dim, dim, 2),  # LSTM layer\n",
    "            SelectItem(0),  # Custom module to select an item from the LSTM output\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.2)  # Dropout layer with a dropout rate of 0.2\n",
    "        self.tf = transforms.Compose([\n",
    "            transforms.Resize(256),  # Resize image to 256x256\n",
    "            transforms.CenterCrop(224),  # Center crop to 224x224\n",
    "        ])\n",
    "\n",
    "    def forward(self, patch, ct, adj):\n",
    "        # Resize and crop the input image patches\n",
    "        x = self.tf(patch.squeeze())\n",
    "\n",
    "        # Extract features from the input image\n",
    "        x = self.ft_extractor(x)\n",
    "        \n",
    "        # Project features to the specified embedding dimension\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        # Apply dropout to the projected features\n",
    "        x = self.dropout(x.squeeze(0)).unsqueeze(0)\n",
    "\n",
    "        # Pass the features through the transformer\n",
    "        x = self.transformer(x + ct).squeeze(0)\n",
    "        \n",
    "        # Apply Graph Convolutional Networks\n",
    "        jk = []\n",
    "        for layer in self.GCN:\n",
    "            x = layer(x, adj.squeeze(0))\n",
    "            jk.append(x.unsqueeze(0))\n",
    "        x = torch.cat(jk, 0)\n",
    "\n",
    "        # Apply LSTM and compute the mean of the LSTM output\n",
    "        x = self.jknet(x).mean(0)\n",
    "        \n",
    "        # Return the final output\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define a custom CNN_ST class that extends pytorch_lightning LightningModule\n",
    "class CNN_ST(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=1e-5, name=\"resnet\", dim=1024, n_pos=128, n_genes=12,\n",
    "                 depth1=2, depth2=8, depth3=4, heads=16,\n",
    "                 zinb=0.25, nb=False, policy='mean', bake=5, lamb=0.5):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.nb = nb\n",
    "        self.zinb = zinb\n",
    "        self.bake = bake\n",
    "        self.lamb = lamb\n",
    "\n",
    "        # Position Embedding\n",
    "        self.x_embed = nn.Embedding(n_pos, dim)\n",
    "        self.y_embed = nn.Embedding(n_pos, dim)\n",
    "\n",
    "        # Feature Extractor (ViT)\n",
    "        self.vit = ViT(\n",
    "            heads=heads, name=name,\n",
    "            dim=dim, depth1=depth1, depth2=depth2, depth3=depth3,\n",
    "            mlp_dim=dim, policy=policy, gcn=True, )\n",
    "\n",
    "        self.n_genes = n_genes\n",
    "\n",
    "        # ZINB Loss\n",
    "        if self.zinb > 0:\n",
    "            if self.nb:\n",
    "                self.hr = nn.Linear(dim, n_genes)\n",
    "                self.hp = nn.Linear(dim, n_genes)\n",
    "            else:\n",
    "                self.mean = nn.Sequential(nn.Linear(dim, n_genes), MeanAct())\n",
    "                self.disp = nn.Sequential(nn.Linear(dim, n_genes), DispAct())\n",
    "                self.pi = nn.Sequential(nn.Linear(dim, n_genes), nn.Sigmoid())\n",
    "\n",
    "        # Data augmentation\n",
    "        self.coef = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim, 1),\n",
    "        )\n",
    "        self.imaug = transforms.Compose([\n",
    "            transforms.RandomGrayscale(0.1),\n",
    "            transforms.RandomRotation(90),\n",
    "            transforms.RandomHorizontalFlip(0.2),\n",
    "        ])\n",
    "\n",
    "        # Regression Module\n",
    "        self.gene_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, n_genes),\n",
    "        )\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, patch, centers, adj):\n",
    "        # Spatial location for Transformer\n",
    "        centers_x = self.x_embed(centers[:, :, 0].long())\n",
    "        centers_y = self.y_embed(centers[:, :, 1].long())\n",
    "        ct = centers_x + centers_y\n",
    "\n",
    "        # Feature Extraction\n",
    "        h = self.vit(patch, ct, adj)\n",
    "\n",
    "        # Gene expression prediction\n",
    "        x = self.gene_head(h)\n",
    "\n",
    "        # ZINB Distribution\n",
    "        extra = None\n",
    "        if self.zinb > 0:\n",
    "            if self.nb:\n",
    "                r, p = self.hr(h)\n",
    "                extra = (r, p)\n",
    "            else:\n",
    "                m = self.mean(h)\n",
    "                d = self.disp(h)\n",
    "                p = self.pi(h)\n",
    "                extra = (m, d, p)\n",
    "\n",
    "        h = self.coef(h)\n",
    "        return x, extra, h\n",
    "    \n",
    "    def aug(self,patch,center,adj):\n",
    "        bake_x=[]\n",
    "        # generate 5 additional image patches\n",
    "        for i in range(self.bake):\n",
    "            new_patch=self.imaug(patch.squeeze(0)).unsqueeze(0)\n",
    "            x,_,h=self(new_patch,center,adj)\n",
    "            bake_x.append((x.unsqueeze(0),h.unsqueeze(0)))\n",
    "        return bake_x\n",
    "    \n",
    "    def distillation(self,bake_x):\n",
    "        new_x,coef=zip(*bake_x)\n",
    "        coef=torch.cat(coef,0)\n",
    "        new_x=torch.cat(new_x,0)\n",
    "        coef=F.softmax(coef,dim=0)\n",
    "        new_x=(new_x*coef).sum(0)\n",
    "        return new_x\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        patch, center, exp, adj, oris, sfs, *_ = batch\n",
    "        adj=adj.squeeze(0)\n",
    "        exp=exp.squeeze(0)\n",
    "\n",
    "        \"\"\" Model inference \"\"\"\n",
    "        pred,extra,h = self(patch, center, adj)\n",
    "\n",
    "        \"\"\" Regression Loss \"\"\"\n",
    "        mse_loss = F.mse_loss(pred, exp)\n",
    "        self.log('mse_loss', mse_loss,on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        \"\"\" ZINB Loss \"\"\"\n",
    "        zinb_loss=0\n",
    "        if self.zinb>0:\n",
    "            if self.nb:\n",
    "                r,p=extra\n",
    "                zinb_loss = NB_loss(oris.squeeze(0),r,p)\n",
    "            else:\n",
    "                m,d,p=extra\n",
    "                zinb_loss = ZINB_loss(oris.squeeze(0),m,d,p,sfs.squeeze(0))\n",
    "        self.log('zinb_loss', zinb_loss,on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        \"\"\" Self-distillation loss \"\"\"\n",
    "        bake_loss=0\n",
    "        bake_x=self.aug(patch,center,adj)\n",
    "        new_pred=self.distillation(bake_x)\n",
    "        bake_loss+=F.mse_loss(new_pred,pred)\n",
    "        self.log('bake_loss', bake_loss,on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        \"\"\" Total Loss \"\"\"\n",
    "        loss = mse_loss + self.zinb*zinb_loss+self.lamb*bake_loss\n",
    "        self.log('train_loss', loss,on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        patch, center, exp, adj, oris, sfs, *_ = batch\n",
    "        adj=adj.squeeze(0)\n",
    "        exp=exp.squeeze(0)\n",
    "\n",
    "        \"\"\" Model Inference \"\"\"\n",
    "        pred,extra,h = self(patch, center, adj)\n",
    "\n",
    "        \"\"\" Regression Loss \"\"\"\n",
    "        mse_loss = F.mse_loss(pred, exp)\n",
    "        self.log('val_loss', mse_loss,on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return mse_loss\n",
    "\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        patch, center, exp, adj, oris, sfs, *_ = batch\n",
    "        adj=adj.squeeze(0)\n",
    "        exp=exp.squeeze(0)\n",
    "\n",
    "        \"\"\" Model Inference \"\"\"\n",
    "        gene_exp,extra,h = self(patch, center, adj)\n",
    "\n",
    "        \"\"\"Pearson correlation coeficient\"\"\"\n",
    "        adata1 = ad.AnnData(gene_exp.cpu().detach().numpy())\n",
    "        adata2 = ad.AnnData(exp.cpu().detach().numpy())\n",
    "        R=get_R(adata1,adata2)[0]\n",
    "        mean_pcc=np.nanmean(R)\n",
    "        self.log('test_mean_PCC', mean_pcc, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # self.hparams available because we called self.save_hyperparameters()\n",
    "        optim=torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        optim_dict = {'optimizer': optim}\n",
    "        return optim_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70907cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from data_vit import ViT_Anndata\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\"\"\"Training loops\"\"\"\n",
    "seed = 12000\n",
    "epochs = 1 # Num epochs\n",
    "dim = 1024 # Hidden layer dimension\n",
    "name = \"resnet\"   # [\"swim_s\", \"efficientnet\", \"resnet\"]\n",
    "fold=0 # LOOCV\n",
    "\n",
    "\"\"\"Load dataset\"\"\"\n",
    "train_loader, val_loader = dataset_wrap(fold = fold, train=True, dataloader= True)\n",
    "test_loader = dataset_wrap(fold = fold, train=False, dataloader= True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbd08770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | x_embed   | Embedding  | 131 K \n",
      "1 | y_embed   | Embedding  | 131 K \n",
      "2 | vit       | ViT        | 97.0 M\n",
      "3 | mean      | Sequential | 12.3 K\n",
      "4 | disp      | Sequential | 12.3 K\n",
      "5 | pi        | Sequential | 12.3 K\n",
      "6 | coef      | Sequential | 1.1 M \n",
      "7 | gene_head | Sequential | 14.3 K\n",
      "-----------------------------------------\n",
      "74.8 M    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "98.3 M    Total params\n",
      "393.388   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 90/90 [02:08<00:00,  1.42s/it, mse_loss_step=0.959, zinb_loss_step=3.440, bake_loss_step=1.5e-5, train_loss_step=1.820] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   3%|▎         | 1/32 [00:00<00:00, 39.89it/s]\u001b[A\n",
      "Validation DataLoader 0:   6%|▋         | 2/32 [00:00<00:03,  9.13it/s]\u001b[A\n",
      "Validation DataLoader 0:   9%|▉         | 3/32 [00:00<00:04,  6.62it/s]\u001b[A\n",
      "Validation DataLoader 0:  12%|█▎        | 4/32 [00:00<00:04,  6.17it/s]\u001b[A\n",
      "Validation DataLoader 0:  16%|█▌        | 5/32 [00:00<00:04,  5.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  19%|█▉        | 6/32 [00:01<00:04,  5.42it/s]\u001b[A\n",
      "Validation DataLoader 0:  22%|██▏       | 7/32 [00:01<00:04,  5.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  25%|██▌       | 8/32 [00:01<00:04,  4.94it/s]\u001b[A\n",
      "Validation DataLoader 0:  28%|██▊       | 9/32 [00:01<00:04,  4.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  31%|███▏      | 10/32 [00:01<00:04,  5.06it/s]\u001b[A\n",
      "Validation DataLoader 0:  34%|███▍      | 11/32 [00:02<00:04,  5.21it/s]\u001b[A\n",
      "Validation DataLoader 0:  38%|███▊      | 12/32 [00:02<00:04,  4.33it/s]\u001b[A\n",
      "Validation DataLoader 0:  41%|████      | 13/32 [00:02<00:04,  4.55it/s]\u001b[A\n",
      "Validation DataLoader 0:  44%|████▍     | 14/32 [00:03<00:03,  4.51it/s]\u001b[A\n",
      "Validation DataLoader 0:  47%|████▋     | 15/32 [00:03<00:03,  4.40it/s]\u001b[A\n",
      "Validation DataLoader 0:  50%|█████     | 16/32 [00:03<00:03,  4.08it/s]\u001b[A\n",
      "Validation DataLoader 0:  53%|█████▎    | 17/32 [00:04<00:03,  4.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  56%|█████▋    | 18/32 [00:04<00:03,  4.10it/s]\u001b[A\n",
      "Validation DataLoader 0:  59%|█████▉    | 19/32 [00:04<00:03,  4.04it/s]\u001b[A\n",
      "Validation DataLoader 0:  62%|██████▎   | 20/32 [00:05<00:03,  3.87it/s]\u001b[A\n",
      "Validation DataLoader 0:  66%|██████▌   | 21/32 [00:05<00:02,  3.91it/s]\u001b[A\n",
      "Validation DataLoader 0:  69%|██████▉   | 22/32 [00:05<00:02,  3.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  72%|███████▏  | 23/32 [00:06<00:02,  3.78it/s]\u001b[A\n",
      "Validation DataLoader 0:  75%|███████▌  | 24/32 [00:06<00:02,  3.82it/s]\u001b[A\n",
      "Validation DataLoader 0:  78%|███████▊  | 25/32 [00:06<00:01,  3.89it/s]\u001b[A\n",
      "Validation DataLoader 0:  81%|████████▏ | 26/32 [00:06<00:01,  3.93it/s]\u001b[A\n",
      "Validation DataLoader 0:  84%|████████▍ | 27/32 [00:06<00:01,  3.95it/s]\u001b[A\n",
      "Validation DataLoader 0:  88%|████████▊ | 28/32 [00:07<00:01,  3.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  91%|█████████ | 29/32 [00:07<00:00,  3.98it/s]\u001b[A\n",
      "Validation DataLoader 0:  94%|█████████▍| 30/32 [00:07<00:00,  4.07it/s]\u001b[A\n",
      "Validation DataLoader 0:  97%|█████████▋| 31/32 [00:07<00:00,  4.17it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 90/90 [02:15<00:00,  1.51s/it, mse_loss_step=0.959, zinb_loss_step=3.440, bake_loss_step=1.5e-5, train_loss_step=1.820, val_loss=0.780]\n",
      "Epoch 0: 100%|██████████| 90/90 [02:15<00:00,  1.51s/it, mse_loss_step=0.959, zinb_loss_step=3.440, bake_loss_step=1.5e-5, train_loss_step=1.820, val_loss=0.780, mse_loss_epoch=2.350, zinb_loss_epoch=14.60, bake_loss_epoch=3.01e-5, train_loss_epoch=6.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 90/90 [02:17<00:00,  1.53s/it, mse_loss_step=0.959, zinb_loss_step=3.440, bake_loss_step=1.5e-5, train_loss_step=1.820, val_loss=0.780, mse_loss_epoch=2.350, zinb_loss_epoch=14.60, bake_loss_epoch=3.01e-5, train_loss_epoch=6.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 25/25 [00:06<00:00,  3.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_mean_PCC       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01107896215079828    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_mean_PCC      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01107896215079828   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  0.12267369204097324  hours\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Define model\"\"\"\n",
    "model = CNN_ST(name=name, dim=dim)\n",
    "setup_seed(seed)\n",
    "\n",
    "\"\"\"Setup trainer\"\"\"\n",
    "logger = pl.loggers.CSVLogger(\"logs\", name=f\"./CNN_ST/{name}_fold{fold}\")\n",
    "trainer = pl.Trainer(accelerator='auto',  callbacks=[EarlyStopping(monitor='val_loss',mode='min')], max_epochs=epochs,logger=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "\"\"\"Save model and clean memory\"\"\"\n",
    "#     torch.save(model.state_dict(),f\"./model/Earlystop/{name}-seed{seed}-epochs{epochs}-sampleIndex{fold}.ckpt\")\n",
    "gc.collect()\n",
    "del train_loader, val_loader, test_loader\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Training time: \", execution_time/3600, \" hours\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
